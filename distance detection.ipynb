{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T09:29:47.027988Z","iopub.status.busy":"2021-11-10T09:29:47.027453Z","iopub.status.idle":"2021-11-10T09:29:59.849343Z","shell.execute_reply":"2021-11-10T09:29:59.848123Z","shell.execute_reply.started":"2021-11-10T09:29:47.027952Z"},"trusted":true},"outputs":[],"source":["!pip install imutils"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-10T09:30:02.771847Z","iopub.status.busy":"2021-11-10T09:30:02.771542Z","iopub.status.idle":"2021-11-10T09:30:03.005585Z","shell.execute_reply":"2021-11-10T09:30:03.004767Z","shell.execute_reply.started":"2021-11-10T09:30:02.771813Z"},"trusted":true},"outputs":[],"source":["# import the necessary packages\n","from imutils import paths\n","import numpy as np\n","import imutils\n","import cv2\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T09:43:11.215156Z","iopub.status.busy":"2021-11-10T09:43:11.214737Z","iopub.status.idle":"2021-11-10T09:43:11.222054Z","shell.execute_reply":"2021-11-10T09:43:11.221419Z","shell.execute_reply.started":"2021-11-10T09:43:11.215125Z"},"trusted":true},"outputs":[],"source":["def find_stickynote(image):\n","    # convert the image to grayscale, blur it, and detect edges\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n","    edged = cv2.Canny(gray, 35, 125)\n","    # find the contours in the edged image and keep the largest one;\n","    # we'll assume that this is our piece of paper in the image\n","    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = imutils.grab_contours(cnts)\n","    c = max(cnts, key = cv2.contourArea)\n","    M = cv2.moments(c)\n","    # compute the bounding box of the of the note region and return it\n","    return cv2.minAreaRect(c), [int(M[\"m10\"] / M[\"m00\"]),int(M[\"m01\"] / M[\"m00\"])]"]},{"cell_type":"markdown","metadata":{},"source":["Let's try to apply the Triangle Similiarity principle in our problem to calculate the distance of the stickynote from camera. The triangle similarity goes something like this: Let’s say we have a marker or object with a known width W. We then place this marker some distance D from our camera. We take a picture of our object using our camera and then measure the apparent width in pixels P. This allows us to derive the perceived focal length F of our camera:\n","\n","F = (P x D) / W\n","\n","For example, let’s say I place a standard piece of 8.5 x 11in piece of paper (horizontally; W = 11) D = 24 inches in front of my camera and take a photo. When I measure the width of the piece of paper in the image, I notice that the perceived width of the paper is P = 248 pixels.\n","\n","My focal length F is then:\n","\n","F = (248px x 24in) / 11in = 543.45"]},{"cell_type":"markdown","metadata":{},"source":["In the sample Image given in the question, It's shown that D=30cm. By calculating the pixel size of the sticky note in the image, we can calculate W."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T09:30:23.490553Z","iopub.status.busy":"2021-11-10T09:30:23.489773Z","iopub.status.idle":"2021-11-10T09:30:23.494567Z","shell.execute_reply":"2021-11-10T09:30:23.493804Z","shell.execute_reply.started":"2021-11-10T09:30:23.49051Z"},"trusted":true},"outputs":[],"source":["def distance_to_camera(knownWidth, focalLength, perWidth):\n","    # compute and return the distance from the maker to the camera\n","    return (knownWidth * focalLength) / perWidth"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T09:30:25.050814Z","iopub.status.busy":"2021-11-10T09:30:25.050538Z","iopub.status.idle":"2021-11-10T09:30:25.05524Z","shell.execute_reply":"2021-11-10T09:30:25.05437Z","shell.execute_reply.started":"2021-11-10T09:30:25.050785Z"},"trusted":true},"outputs":[],"source":["# initialize the known distance from the camera to the object, which\n","# in this case is 200cm\n","KNOWN_DISTANCE = 200\n","# initialize the known object width, which in this case, we assume the sticky note of\n","# size is 100cm wide\n","KNOWN_WIDTH = 100"]},{"cell_type":"markdown","metadata":{},"source":["**I am making the assumption that the contour with the largest area is our sticky note. This assumption works for this particular case when our webcam is not moving and no new object is introduced, but in reality finding the sticky note in an image is highly application specific and we can use either cascadeclassifier, YOLO algorithm or  other deep learning models which need training and test data. SO for the sake of simplicity, I have decided to move on with this model as the objective is to build a simple model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T09:58:08.902259Z","iopub.status.busy":"2021-11-10T09:58:08.90198Z","iopub.status.idle":"2021-11-10T09:58:09.677234Z","shell.execute_reply":"2021-11-10T09:58:09.676121Z","shell.execute_reply.started":"2021-11-10T09:58:08.902229Z"},"trusted":true},"outputs":[],"source":["# from our camera, then find the sticky note in the image, and initialize\n","# the focal length\n","image = cv2.imread(\"../input/q-webcam-feed/webcam_feed.jpg\")\n","sticky_note, centre = find_stickynote(image)\n","focalLength = (sticky_note[1][0] * KNOWN_DISTANCE) / KNOWN_WIDTH\n","dist = distance_to_camera(KNOWN_WIDTH, focalLength, sticky_note[1][0])\n","# draw a bounding box around the image and display it\n","box = cv2.cv.BoxPoints(sticky_note) if imutils.is_cv2() else cv2.boxPoints(sticky_note)\n","box = np.int0(box)\n","plt.figure(figsize=(15,15))\n","plt.plot([centre[0],box[1][0]-100],[centre[1],box[1][1]-50],color=\"yellow\", linewidth=3)\n","plt.plot([box[1][0],box[2][0]],[box[1][1],box[2][1]],color=\"white\", linewidth=3)\n","plt.plot([box[2][0],box[3][0]],[box[2][1],box[3][1]],color=\"white\", linewidth=3)\n","plt.plot([box[3][0],box[0][0]],[box[3][1],box[0][1]],color=\"white\", linewidth=3)\n","plt.plot([box[0][0],box[1][0]],[box[0][1],box[1][1]],color=\"white\", linewidth=3)\n","plt.text(box[1][0]-160, box[1][1]-60, \"{} cm\".format(str(dist)), color=\"orange\", fontdict={\"fontsize\":20,\"fontweight\":'bold'})\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Now for live footage, we can use a forloop that perform the same task for continuos frames at a fixed interval."]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"},"vscode":{"interpreter":{"hash":"75e061092d9b34b5b6dca6223111a63e0035aad888c282ede96871793f5e93d2"}}},"nbformat":4,"nbformat_minor":4}
